seed_everything: 3407

data:
  class_path: decoder.dataset.VocosDataModule
  init_args:
    train_params:
      filelist_path: train_filelist.txt
      sampling_rate: 24000
      num_samples: 72000
      batch_size: 40  # 20
      num_workers: 8

    val_params:
      filelist_path: dev_filelist.txt
      sampling_rate: 24000
      num_samples: 72000
      batch_size: 10   # 10
      num_workers: 8

model:
  class_path: decoder.experiment_nerd.WavTokenizer
  init_args:
    use_nerd: true
    use_discriminator: false
    train_nerd_only: true
    sample_rate: 24000
    initial_learning_rate: 2e-4
    mel_loss_coeff: 45
    mrd_loss_coeff: 1.0
    num_warmup_steps: 0 # Optimizers warmup steps
    pretrain_mel_steps: 0  # 0 means GAN objective from the first iteration

    # automatic evaluation
    evaluate_utmos: true
    evaluate_pesq: true
    evaluate_periodicty: true

    resume: true
    resume_config: ../WavTokenizer_models/wavtokenizer_smalldata_frame40_3s_nq1_code4096_dim512_kmeans200_attn.yaml
    resume_model: ../WavTokenizer_models/WavTokenizer_small_600_24k_4096.ckpt

    feature_extractor:
      class_path: decoder.feature_extractors.EncodecFeatures
      init_args:
        encodec_model: encodec_24khz
        bandwidths: [6.6, 6.6, 6.6, 6.6]
        train_codebooks: true
        num_quantizers: 1  
        dowmsamples: [6, 5, 5, 4]
        vq_bins: 4096
        vq_kmeans: 200
        use_nerd: True

        nerd_config:
          class_path: nerd.nerd.NERDConfig
          init_args:
            dz: 8
            hidden: 256
            Kz: 256
            batch_u: 512
            beta: 20.0
            lr: 5e-4
            buffer_size: 200_000
            rd_Kz: 1024
            rd_bisect_iters: 12

    backbone:
      class_path: decoder.models.VocosBackbone
      init_args:
        input_channels: 512
        dim: 768
        intermediate_dim: 2304
        num_layers: 12
        adanorm_num_embeddings: 4

    head:
      class_path: decoder.heads.ISTFTHead
      init_args:
        dim: 768
        n_fft: 2400 
        hop_length: 600
        padding: same

trainer:
  # resume_from_checkpoint: ../WavTokenizer_models/WavTokenizer_small_600_24k_4096.ckpt
  logger:
    class_path: pytorch_lightning.loggers.TensorBoardLogger
    init_args:
      save_dir: ./result/train/WavTokenizer_small_600_24k_4096_nerdonly_beta20/
      # name: lightning_logs
      # version: 0
  callbacks:
    - class_path: pytorch_lightning.callbacks.LearningRateMonitor
    - class_path: pytorch_lightning.callbacks.ModelSummary
      init_args:
        max_depth: 2
    - class_path: pytorch_lightning.callbacks.ModelCheckpoint
      init_args:
        monitor: val_loss
        filename: wavtokenizer_checkpoint_{epoch}_{step}_{val_loss:.4f}
        save_top_k: 10
        save_last: true
    - class_path: decoder.helpers.GradNormCallback

  # Lightning calculates max_steps across all optimizer steps (rather than number of batches)
  # This equals to 1M steps per generator and 1M per discriminator
  max_steps: 72500 # A little over 3 epochs at BS40 on LibriTTS Train (8049 batches per epoch)
  # max_steps: 500000
  # You might want to limit val batches when evaluating all the metrics, as they are time-consuming
  limit_val_batches: 10
  accelerator: gpu
  strategy: ddp
  devices: [0]
  log_every_n_steps: 1000
